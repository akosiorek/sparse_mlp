{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Implemented with Tensorflow v1.5\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('mnist', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "max_train_itr = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparse_fully_connected(inpt, n_out, n_params=None, density=1., use_bias=True):\n",
    "    \"\"\"Multiplies `inpt` with a sparse matrix.\n",
    "\n",
    "    :param inpt: tf.Tensor\n",
    "    :param n_out: int, size of the output vector\n",
    "    :param n_params: int, number of learnable parameters in the matrix. If None,\n",
    "        the number of parameters is equal to `density` times the number of parameters\n",
    "        that a dense matrix would have.\n",
    "    :param density: float in (0, 1.]; number of parameters relative to the number of\n",
    "    parameters in a dense matrix.\n",
    "    \"param use_bias: boolean, uses bias if True.\n",
    "    \n",
    "    :return: tf.Tensor\n",
    "    \"\"\"\n",
    "    n_in = int(inpt.shape[-1])\n",
    "    shape = [n_in, n_out]\n",
    "    dense_n_params = int(np.prod(shape))\n",
    "    \n",
    "    if n_params is None:\n",
    "        assert 0 < density <= 1.\n",
    "        n_params = int(dense_n_params * density)\n",
    "        \n",
    "    assert 0. < n_params <= dense_n_params\n",
    "    \n",
    "    params = tf.get_variable('weights', shape=n_params, dtype=tf.float32, trainable=True)\n",
    "    \n",
    "    if n_params == dense_n_params:\n",
    "        w = tf.reshape(params, shape)\n",
    "    else:\n",
    "        linear_idx = np.random.choice(dense_n_params, size=n_params, replace=False)\n",
    "        idx = np.unravel_index(linear_idx, shape)\n",
    "        idx = np.stack(idx, 1)\n",
    "        w = tf.scatter_nd(idx, params, shape)\n",
    "    \n",
    "    w_is_sparse = (n_params < 0.5 * dense_n_params)\n",
    "\n",
    "    output = tf.matmul(inpt, w, b_is_sparse=w_is_sparse)\n",
    "    if use_bias:\n",
    "        bias = tf.get_variable('bias', shape=n_out, dtype=tf.float32, trainable=True)\n",
    "        output = tf.nn.bias_add(output, bias)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [batch_size, 28**2], 'img')\n",
    "y = tf.placeholder(tf.int32, [batch_size], 'label')\n",
    "\n",
    "logits = sparse_fully_connected(x, 10, density=.234)\n",
    "# logits = sparse_fully_connected(x, 10, n_params=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "train_step = opt.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n_params = 0\n",
    "\n",
    "print 'Trainable variables:'\n",
    "for v in tf.trainable_variables():\n",
    "    shape = v.shape.as_list()\n",
    "    n_params = int(np.prod(shape))\n",
    "    total_n_params += n_params\n",
    "    print '\\t{}, shape={}, n_params={}'.format(v.name, shape, n_params)\n",
    "print 'Total number of trainable parameters:', total_n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_itr = sess.run(global_step)\n",
    "while train_itr < max_train_itr:\n",
    "    xx, yy = mnist.train.next_batch(batch_size)\n",
    "    fd = {x: xx, y:yy}\n",
    "    train_itr, l, _ = sess.run([global_step, loss, train_step], fd)\n",
    "    \n",
    "    if train_itr % 1000 == 0:\n",
    "        print train_itr, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
